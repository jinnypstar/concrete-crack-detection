# -*- coding: utf-8 -*-
"""deep learning hw1-inference-fastapi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rBbk0segC96Mz9RaMFpidJdE-30LfM4K

## fastapi 를 설치한다
"""

! pip install fastapi uvicorn

import os
import glob
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader, random_split
from PIL import Image

"""## 이미지데이터 위치"""

# 데이터 경로
data_dir = '/content/drive/MyDrive/crack_1000'
model_file = data_dir + '/resnet_weights.pth'


# 디바이스 설정
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"device={device}")

"""## 딥러닝 모델 정의 및 weight 로딩"""

# 1. 모델 정의 및 가중치 로드
model = models.resnet18(pretrained=False)
model.fc = nn.Linear(model.fc.in_features, 2)  # 이진 분류를 위한 출력 레이어 수정
model.load_state_dict(torch.load(model_file, map_location=device))
model.eval()  # 추론 모드로 전환

# 2. 이미지 전처리 함수 정의
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

"""## 추론하기 (이미지 classification)
*   이미지 파일 읽기
*   추론하기 (predict)
*   2개의 predict 값 중에서 큰값으로 positive, negative 결정하기

"""

def inference(image_name):
    # 3. 이미지 로드 및 전처리
    image_path = image_name  # 추론할 이미지 파일 경로
    image = Image.open(image_path).convert('RGB')  # 이미지 로드 및 RGB로 변환
    input_tensor = preprocess(image)  # 전처리 수행
    input_batch = input_tensor.unsqueeze(0)  # 배치 차원 추가 (1, C, H, W)

    # 4. 모델을 통한 추론
    with torch.no_grad():  # 추론이므로 그라디언트 비활성화
        output = model(input_batch)
        print(output)
        # 두개 값에 중에 큰 값을 선택한다
        _, predicted_class = torch.max(output, 1)

    # 5. 결과 출력
    class_names = ['negative', 'positive']  # 클래스 이름 정의
    print(f"AI: {image_name} --> {class_names[predicted_class.item()]}")
    return class_names[predicted_class.item()]

# 샘플로 확인해보기 1
inference(data_dir + '/negative/00020.jpg')

# 샘플로 확인해보기 2
inference(data_dir + '/positive/00020.jpg')

"""# fastapi 로 서빙하기"""

from fastapi import FastAPI
from pydantic import BaseModel
from typing import List

import requests
import uvicorn

app = FastAPI()

"""## colab에서 fastapi를 사용할 때 nest_asyncio 필요


"""

# chatgpt에서 알려줌
import nest_asyncio
nest_asyncio.apply()

"""## 이미지대문 페이지
*  인사말 하기
"""

# 대문페이지 (/ 루트 페이지)
@app.get("/")
async def get_index():
    return "hello. this image AI demo page !!"

"""## 이미지 인식 페이지
*    '/imageai/positive/00001.jpg' 이런식으로 입력해야 함
"""

# 이미지 인식 페이지
@app.get("/imageai/{label}/{img}", )
async def get_image_ai(label: str, img: str):
    # 이미지 파일 경로를 지정합니다.
    # ~~~~~/positive/00010.jpg
    # 데이터 경로
    global data_dir

    image_path = f"{data_dir}/{label}/{img}"

    # 이미지 파일이 존재하는지 확인합니다.
    if os.path.exists(image_path):
        # 파일이 존재하면 파일 응답을 반환합니다.
        print(f"file {image_path} ok")
        inf_result = inference(image_path)
        result = f"이미지 인식 결과: {img} --> {inf_result}"
        return {"result": result}

    else:
        # 파일이 존재하지 않으면 404 오류를 반환합니다.
        return {"error": f"Image not found - {image_path}"}

# FastAPI 서버를 별도의 스레드에서 실행
import threading

def run():
    uvicorn.run(app, host="0.0.0.0", port=8000)

# FastAPI 서버 실행 스레드
threading.Thread(target=run).start()

"""## ngrok 설치
*   **colab에서** 띄운 fastapi 웹서버를 접근할 수 있도록 한다.


"""

! pip install pyngrok

! ngrok authtoken "2o367NqCpm1gBquAMGtvdAgun3k_3BAjKMTFJa77jYwuAc1Ps"

from pyngrok import ngrok

# ngrok을 통해 포트 8000에 접근
public_url = ngrok.connect(8000)
print("Public URL:", public_url)

## 성공하면 이렇게 나옴
## Public URL: NgrokTunnel: "https://db46-34-145-66-177.ngrok-free.app" -> "http://localhost:8000"

# ngrok 를 종료하고 싶을때

ngrok.disconnect(public_url)  # 특정 URL을 종료

